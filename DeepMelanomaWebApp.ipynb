{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Deep Melanoma Classifier</center></h1>\n",
    "\n",
    "\n",
    "[Melanoma](https://www.mayoclinic.org/diseases-conditions/melanoma/symptoms-causes/syc-20374884) is the most serious type of skin cancer, develops in the cells (melanocytes) that produce melanin, early diagnosis is key for recovery.\n",
    "\n",
    "-  The model in this app is based on the EfficientNet B5 architecture, trained on the [SIIM](https://siim.org/) Melanoma dataset.\n",
    "- The model achieves SOTA performance of 0.9297 AUROC on the test data utilizing heavy [Test Time Augmentation](https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d) (T.T.A.). \n",
    "- This web app allows the user to set the number of T.T.A.s\n",
    "\n",
    "**NOTE** This is a proof of concept for research purposes and the result obatined here should not be used as FINAL diagnosis. Always seek professional medical help in a clinical setting for final diagnosis.\n",
    "    \n",
    "    \n",
    "<h3><center>Directions For Use:</center></h3>   \n",
    "\n",
    "    \n",
    "1. Select the desired # of Test Time Augmentations\n",
    "2. Upload an image of the skin lesion you want to check for Melanoma\n",
    "3. You will see in realtime, the images of test time augmentations and the corresponding model prediction.\n",
    "4. Final prediction (avergae of all TTA predictions) is displayed along with the original image uploaded at the end.    \n",
    "\n",
    "**Note:** Model Prediction is the Probability of skin legion being Melanoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the req libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import cv2\n",
    "import io\n",
    "from ipywidgets import VBox\n",
    "from tensorflow.keras.preprocessing.image import apply_affine_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the model\n",
    "model_input = tf.keras.Input(shape=(248, 248, 3), name='imgIn')\n",
    "dummy = tf.keras.layers.Lambda(lambda x:x)(model_input)    \n",
    "outputs = []    \n",
    "\n",
    "## get the attributes of efn - effNet\n",
    "constructor = getattr(efn, 'EfficientNetB5')\n",
    "## remove top, use imagenet weights\n",
    "x = constructor(include_top=False, weights='imagenet', \n",
    "                input_shape=(248, 248, 3), \n",
    "                pooling='avg')(dummy)\n",
    "\n",
    "## add a dense layer\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "outputs.append(x)\n",
    "    \n",
    "## create model\n",
    "model = tf.keras.Model(model_input, outputs, name='effb5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load weights into model\n",
    "model.load_weights('EfficientNetB5-weights.15.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##upload button\n",
    "btn_upload = widgets.FileUpload(accept ='image/*'\n",
    "                                , multiple = True\n",
    "                                , align_items='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## slider for tta\n",
    "sldr = widgets.IntSlider(value=10\n",
    "                         , min=5\n",
    "                         , max=50\n",
    "                         , step=1\n",
    "                         , description='T.T.A.:'\n",
    "                         , disabled=False\n",
    "                         , continuous_update=False\n",
    "                         , orientation='horizontal'\n",
    "                         , align_items='center'\n",
    "                         , readout=True\n",
    "                         , readout_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output()\n",
    "lbl_pred = widgets.Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the onclick event for upload button\n",
    "def on_click(change):\n",
    "    img = widgets.Image(value = btn_upload.data[-1])\n",
    "    out.clear_output()\n",
    "    with out: display(img)\n",
    "    image = np.array(Image.open(io.BytesIO(btn_upload.data[-1])))/255\n",
    "    pred_ls =[]\n",
    "    for i in range(sldr.value):\n",
    "        transformation = apply_affine_transform(image\n",
    "                                                , tx = (np.random.normal(0, 1, 1)[0])*6\n",
    "                                                , ty = (np.random.normal(0, 1, 1)[0])*6\n",
    "                                                , theta = 180 * (np.random.normal(0, 1, 1)[0])\n",
    "                                                , zx = 1 + (np.random.normal(0, 1, 1)[0])/6\n",
    "                                                , zy = 1 + (np.random.normal(0, 1, 1)[0])/6\n",
    "                                                , shear = (np.random.normal(0, 1, 1)[0])*1.5\n",
    "                                                )\n",
    "\n",
    "        img1 = tf.image.random_flip_left_right(transformation)\n",
    "        #img1 = tf.image.random_hue(img1, 0.01)\n",
    "        #img1 = tf.image.random_saturation(img1, 0.7, 1.3)\n",
    "        img1 = tf.image.random_contrast(img1, 0.8, 1.2)\n",
    "        img1 = tf.image.random_brightness(img1, 0.1)\n",
    "        input_arr = tf.image.resize(img1, [248,248])\n",
    "        out.clear_output()\n",
    "        img2 = Image.fromarray(((np.array(input_arr)*255).astype(np.int8)), 'RGB')\n",
    "        with out: display(img2)\n",
    "        input_arr = tf.expand_dims(input_arr, axis=0)\n",
    "        pred = model.predict(input_arr, batch_size=1)[0][0]\n",
    "        pred_ls.append(pred)\n",
    "        lbl_pred.value = f'T.T.A. # {i+1} Prediction :{ str(round(pred,2))}'\n",
    "        \n",
    "    out.clear_output()\n",
    "    img = tf.image.resize(image, [248,248])\n",
    "    img = Image.fromarray(((np.array(img)*255).astype(np.int8)), 'RGB')\n",
    "    with out: display(img)\n",
    "    ans = str(round(np.mean(pred_ls),2))    \n",
    "    lbl_pred.value = f'Final Probability of Melanoma for the uploaded(above) image { ans}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload.observe(on_click, names=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##organize widgets\n",
    "display(VBox([widgets.Label('Select the # Test Time Augmentations ( T.T.A. )')\n",
    "              , sldr\n",
    "              , widgets.Label('Select your image')\n",
    "              , btn_upload\n",
    "              , out\n",
    "              ,lbl_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PhaleoHealth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
